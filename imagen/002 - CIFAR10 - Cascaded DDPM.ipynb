{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49103f08-056e-4dec-b26c-6f29ed5e606f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# Code for Diffusion Models\n",
    "# Ref: https://github.com/dome272/Diffusion-Models-pytorch\n",
    "# Code for Implementation of Imagen, Google's Text-to-Image Neural Network, in Pytorch \n",
    "# Ref: https://github.com/lucidrains/imagen-pytorch\n",
    "######################\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch import optim\n",
    "from helpers import *\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bcb3d4-62c7-4db3-9abf-b09bdc34949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bcf66-65ab-47ad-a9d3-ac2c4abe78a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf models/*\n",
    "!rm -rf results/*\n",
    "!rm -rf runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f3085-a0d5-497a-a433-ba5de49c48a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(\"./imagen/\")\n",
    "\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer, NullUnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d73482-aa23-4bc0-9a8d-38959e8d5549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unet1 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True)\n",
    ")\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True)\n",
    ")\n",
    "\n",
    "unets = [unet1, unet2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b571f66-a8f0-4152-9ca4-96c3fa2afc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(trainer, n_images, label_embeds=None, continuous_embeds=None):\n",
    "    x = trainer.sample(batch_size=n_images, \n",
    "                       label_embeds=label_embeds,\n",
    "                       continuous_embeds=continuous_embeds,\n",
    "                       use_tqdm=True)\n",
    "    x = (x.clamp(-1, 1) + 1) / 2\n",
    "    x = (x * 255).type(torch.uint8)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8d63e-ea2d-41ed-b99d-ad289eb91dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    setup_logging(args.run_name)\n",
    "    device = args.device\n",
    "    dataloader = args.dataloader\n",
    "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
    "    epoch = 0\n",
    "    \n",
    "    for k in range(1, len(unets)+1):\n",
    "        trainer = ImagenTrainer(imagen, lr=args.lr, verbose=False).cuda()\n",
    "        try:\n",
    "            ckpt_path = os.path.join(\"models\", args.run_name, f\"ckpt_{k}.pt\")\n",
    "            ckpt_trainer_path = os.path.join(\"models\", args.run_name, f\"ckpt_trainer_{k}.pt\")\n",
    "            checkpoint = torch.load(ckpt_path)\n",
    "            if device == \"cuda\": trainer.load(ckpt_trainer_path)\n",
    "            else: trainer.load(ckpt_trainer_path, map_location=torch.device('cpu'))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            loss = checkpoint['loss']\n",
    "            logging.info(f\"Resuming training from epoch: {start_epoch+1} for unet_{k}\")  \n",
    "            if (start_epoch+1) >= args.epochs: \n",
    "                logging.info(f\"No more epochs to train for unet_{k}\")\n",
    "            epoch = start_epoch+1\n",
    "        except FileNotFoundError:\n",
    "            start_epoch = -1\n",
    "            loss = None\n",
    "            logging.info(f\"Starting training from scratch for unet_{k}\")\n",
    "            epoch = 0\n",
    "\n",
    "        for epoch in range(start_epoch+1, args.epochs):\n",
    "            logging.info(f\"Starting epoch {epoch}:\")\n",
    "            pbar = tqdm(dataloader)\n",
    "            for i, (images, labels) in enumerate(pbar):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                continuous = torch.rand((args.batch_size, args.continuous_dim)).to(device)\n",
    "               \n",
    "                loss = trainer(images=images, label_embeds=labels, \n",
    "                               continuous_embeds=continuous,\n",
    "                               unet_number=k)\n",
    "                trainer.update(unet_number=k)\n",
    "\n",
    "                pbar.set_postfix({f\"MSE_{k}\":loss})\n",
    "                logger.add_scalar(f\"MSE_{k}\", loss, global_step=epoch*len(dataloader)+i)\n",
    "\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'loss': loss\n",
    "            }\n",
    "            trainer.save(os.path.join(\"models\", args.run_name, f\"ckpt_trainer_{k}.pt\"))\n",
    "            torch.save(checkpoint, os.path.join(\"models\", args.run_name, f\"ckpt_{k}.pt\"))\n",
    "\n",
    "            logging.info(f\"Completed epoch {epoch}.\")\n",
    "        \n",
    "            if True:\n",
    "                logging.info(f\"Starting sampling for epoch {epoch}:\")\n",
    "                trainer = ImagenTrainer(imagen, lr=args.lr, verbose=False).cuda()\n",
    "                for k in range(1, len(unets)+1):\n",
    "                    ckpt_trainer_path = os.path.join(\"models\", args.run_name, f\"ckpt_trainer_{k}.pt\")\n",
    "                    if device == \"cuda\": trainer.load(ckpt_trainer_path)\n",
    "                    else: trainer.load(ckpt_trainer_path, map_location=torch.device('cpu'))\n",
    "                n_images = 2\n",
    "                labels = torch.randint(0, 10, (n_images, )).to(device)\n",
    "                continuous = torch.rand((n_images, args.continuous_dim)).to(device)\n",
    "                ema_sampled_images = sample(trainer, n_images=n_images, \n",
    "                                            label_embeds=labels, \n",
    "                                            continuous_embeds=continuous)\n",
    "                plot_images(ema_sampled_images)\n",
    "                save_images(ema_sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}_ema.jpg\"))\n",
    "                logging.info(f\"Completed sampling for epoch {epoch}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539e79f-cbd8-4bd6-9102-494436939736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "class DDPMArgs:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "args = DDPMArgs()\n",
    "args.run_name = \"DDPM_cascaded\"\n",
    "args.epochs = 1\n",
    "args.batch_size = 8\n",
    "args.image_size = 64\n",
    "args.num_classes = 10\n",
    "args.continuous_embed_dim = 5\n",
    "args.dataset_path = r\"/rds/general/user/zr523/home/cifar10/cifar10-64/train\"\n",
    "args.device = \"cuda\"\n",
    "args.lr = 3e-4\n",
    "args.experiment = True\n",
    "args.subset_data = 1000\n",
    "\n",
    "args.dataloader = get_cifar10_data(args)\n",
    "logging.info(f\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0071a1f-ea96-4275-9abe-056fc72eab37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagen = Imagen(\n",
    "    unets = unets,\n",
    "    condition_on_labels = True,\n",
    "    label_embed_dim = args.num_classes,\n",
    "    condition_on_continuous = True,\n",
    "    continuous_embed_dim = args.continuous_embed_dim,\n",
    "    image_sizes = (64, 64),\n",
    "    timesteps = 1000,\n",
    "    cond_drop_prob = 0.1\n",
    ")\n",
    "\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be7960-0f4b-4d3b-aac9-18e474487c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
